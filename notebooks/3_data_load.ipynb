{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction to this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to explain the process followed to load the scraped (extracted) and transformed data in 2 ways:\n",
    "- Saved as checkpoint .csv files in the local machine\n",
    "- Loaded as table records into a databe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Save as csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of loading the files as csv are quite straight forward and is performed via the ``save_csv()`` function, that can be found at `src/support/data_load_support.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load to database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process to load as a database includes:\n",
    "- Creating a database\n",
    "- Creating the tables where the records will be inserted\n",
    "- Inserting the transformed records into the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For that matter, a database structure design must be created, for which the following is the proposed SQL schema:\n",
    "\n",
    "```sql\n",
    "DROP TABLE IF EXISTS products, categories, subcategories, prices, supermarkets, supermarket_product, brands CASCADE;\n",
    "\n",
    "CREATE TABLE categories (\n",
    "    category_id SERIAL PRIMARY KEY,\n",
    "    category_name VARCHAR(100) NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE subcategories (\n",
    "    subcategory_id SERIAL PRIMARY KEY,\n",
    "    category_id INT REFERENCES categories(category_id) ON DELETE CASCADE ON UPDATE CASCADE, -- if category is changed, change here too. If deleted, subcategory no longer needed\n",
    "    subcategory_name VARCHAR(100) NOT NULL,\n",
    "    distinction VARCHAR(100),\n",
    "    eco BOOLEAN\n",
    ");\n",
    "\n",
    "CREATE TABLE brands (\n",
    "    brand_id SERIAL PRIMARY KEY,\n",
    "    brand_name VARCHAR(100) NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE products (\n",
    "    product_id SERIAL PRIMARY KEY,\n",
    "    brand_id INT REFERENCES brands(brand_id) ON DELETE SET NULL ON UPDATE CASCADE, -- if brand_id is changed, change here too. if deleted, remove category from product\n",
    "    subcategory_id INT REFERENCES subcategories(subcategory_id) ON DELETE SET NULL ON UPDATE CASCADE, -- if category is changed, change here too. if deleted, remove category from product\n",
    "    product_name_norm VARCHAR(200) NOT NULL,\n",
    "    quantity NUMERIC,\n",
    "    units VARCHAR(50),\n",
    "    volume_weight NUMERIC\n",
    ");\n",
    "\n",
    "CREATE TABLE supermarkets (\n",
    "    supermarket_id SERIAL PRIMARY KEY,\n",
    "    supermarket_name VARCHAR(100) NOT NULL,\n",
    "    product_name_supermarket VARCHAR(200)\n",
    ");\n",
    "\n",
    "CREATE TABLE supermarket_product (\n",
    "    supermarket_product_id SERIAL PRIMARY KEY,\n",
    "    supermarket_id INT REFERENCES supermarkets(supermarket_id) ON DELETE CASCADE ON UPDATE CASCADE, -- if supermarket is deleted, interation is no longer needed\n",
    "    product_id INT REFERENCES products(product_id) ON DELETE CASCADE ON UPDATE CASCADE, -- if product is deleted, interation is no longer needed\n",
    "    facua_url VARCHAR(255)\n",
    ");\n",
    "\n",
    "CREATE TABLE prices (\n",
    "    price_id SERIAL PRIMARY KEY,\n",
    "    supermarket_product_id INT REFERENCES supermarket_product(supermarket_product_id) ON DELETE CASCADE ON UPDATE CASCADE, -- if category is changed, change here too. If deleted, subcategory no longer needed\n",
    "    date DATE NOT NULL,\n",
    "    price_amount NUMERIC(10, 2) NOT NULL\n",
    ");\n",
    "```\n",
    "\n",
    "Each table has been thought as to keep the minimum double information as possible (normalization). For that reason, the intermediate table between products and supermarkets has been made, where products is a product standardization table, supermarkets is self explanatory and the intermediate is where the whole denomination of each given product at each given supermarket is provided. From that supermarket_product table id, the historical prices relation is obtained.\n",
    "\n",
    "To the normalization performed, there is perhaps the exception of \"subcategories\", where another extra table could have been created for distinctions and eco tag. But given the negligible size memory of this project and the already substantial amount of JOINs that it requires to gather all the information, it was considered non-vital, albeit recognizably less efficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Database and record insertion approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For this data schema to be created, a database must have been created previously. This is has been done through DBeaver's GUI rather than through code, for this project, due to its ease. The creation of the tables, however, has been done through code and the tables are dropped and re-created each time the ETL runs.\n",
    "\n",
    "The dropping and recreation of the tables is like so because of the exploratory nature of this project. It ensures a clean run every time. However, if the project were to be extended, registering the history of prices for a longer period, then it would make sense to modify the ETL to only ingest the latest price and then not drop the tables everytime, just insert a new record per product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Database schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To consult how the tables are created and how records are inserted, please refer to `src/support/data_load_support.py`. The database Entity-Relation diagram once the tables are created is the following:\n",
    "\n",
    "![E-R-diagram](../assets/entity_relation_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Data insertion order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trickiest part of the data load pipeline is correctly setting the order of insertion for the tables at hand. It is necessary to start by the tables that bear no reference to the others. Given that constraint, the order of loading as per the insert functions at `src/support/data_load_support.py` integrated in `src/data_etl.py` is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Categories\n",
    "2. Subcategories \n",
    "3. Brands\n",
    "4. Supermarkets\n",
    "5. Products\n",
    "6. Supermarkets_products\n",
    "7. Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the insert functions at `src/support/data_load_support.py` performs a SELECT to check if the record at hand already exists. If it does not, it is created. Either way, the id of the product is returned by the function so the next referenced table insert has it as a Foreign Key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusion of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to consult the analysis extracted ouf ot this data, please refer to the notebook at `notebooks/4_data_analysis.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-supermercados_analisis",
   "language": "python",
   "name": "my-supermercados_analisis"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
